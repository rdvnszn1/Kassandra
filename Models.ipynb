{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.decomposition as SKLDec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sklearn.model_selection as SKLSel\n",
    "import sklearn.neural_network as SKANN\n",
    "import sklearn.metrics as SKLMet\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import sklearn.feature_selection as fs\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics  import  accuracy_score , confusion_matrix,f1_score,precision_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import sklearn.svm as SVM\n",
    "import sklearn.ensemble as Ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ResultInfo(TestReal,TestPredicted,MethodName):\n",
    " \n",
    "\n",
    "    ResultData = pd.DataFrame(columns=['F1Score', 'AccurancyRate', 'MSE', 'MAE', 'PrecisionScore'])\n",
    "\n",
    "    # Forecasting Accuracy\n",
    "    ANNAbsError = SKLMet.mean_absolute_error(TestReal, TestPredicted)\n",
    "    ANNSeqError = SKLMet.mean_squared_error(TestReal, TestPredicted)\n",
    "    ANNMeanSqEror = np.sqrt(ANNSeqError)\n",
    "\n",
    "    f1score = f1_score(TestReal, TestPredicted, average='macro')\n",
    "\n",
    "    PrecisionScore = precision_score(TestReal, TestPredicted,average='macro')\n",
    "\n",
    "    AccurScore = accuracy_score(TestReal, TestPredicted)\n",
    "\n",
    "    ResultData.loc[MethodName] = [f1score, AccurScore, ANNMeanSqEror, ANNAbsError, PrecisionScore]\n",
    "\n",
    "    return ResultData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ResultGraph(TestReal,TestPredicted,MethodName):\n",
    "    # Testing Chart\n",
    "#     Predicted = pd.DataFrame(TestPredicted, index=TestReal.index)\n",
    "#     fig1, ax = plt.subplots()\n",
    "#     ax.plot(TestReal)\n",
    "#     ax.plot(Predicted, label='ANNForecast')\n",
    "#     plt.legend(loc='upper left')\n",
    "#     plt.title(MethodName+' Testing Chart')\n",
    "#     plt.ylabel('Log Returns')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    ''' Plot confusion matrix for given classifier and data. '''\n",
    "\n",
    "    # Define label names and get confusion matrix values\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "\n",
    "    cm = confusion_matrix(TestReal, TestPredicted)\n",
    "\n",
    "    # Check if matrix should be normalized\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum()\n",
    "\n",
    "    # Configure figure\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\": False})\n",
    "    fig = plt.figure(1)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    plt.title('Confusion Matriks for '+MethodName)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCADimensionFinder(TrainingPCA,NumberOfFeatures):\n",
    "\n",
    "    CutThreshold = 1/NumberOfFeatures\n",
    "\n",
    "    PCAExpVarValues=pd.DataFrame(TrainingPCA.explained_variance_ratio_,columns=['EXPVar'])\n",
    "\n",
    "    PCAExpVarValues.loc[:,'SUM'] =(PCAExpVarValues).cumsum()\n",
    "\n",
    "    PCAExpVarValues.loc[:,'Diff']=(PCAExpVarValues.SUM - PCAExpVarValues.SUM.shift(1))\n",
    "\n",
    "    PCAExpVarValues.loc[PCAExpVarValues.Diff>CutThreshold,'Control']=True\n",
    "    PCAExpVarValues.loc[PCAExpVarValues.Diff<CutThreshold,'Control']=False\n",
    "    ComponentsNumber= len(PCAExpVarValues[PCAExpVarValues.Control==True])+1\n",
    "\n",
    "    return ComponentsNumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ANNResulter(MethodName, TrainingFeutres, TrainingTarget, TestFeatures, TestTarget,Resulter=ResultInfo):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    TSCV = SKLSel.GridSearchCV(SKANN.MLPClassifier(), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                               param_grid={\"alpha\": [0.0001, 0.001, 0.010, 0.100]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.alpha\n",
    "\n",
    "    print(\"== Multi-Layer Perceptron Method Algorithm Training Optimal Parameter Selection ==\")\n",
    "    print(\"Artificial Neural Network Regression  Optimal  Regularization: \", TCSVPar)\n",
    "    print(\"\")\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    ANNTraining = SKANN.MLPClassifier(alpha=TCSVPar).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Testing\n",
    "    ANNTesting = ANNTraining.predict(TestFeatures)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Forecasting\n",
    "    # Forecasting for Trading Subset\n",
    "\n",
    "    return ResultInfo(TestTarget,ANNTesting,MethodName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoostesulter(MethodName, TrainingFeutres, TrainingTarget, TestFeatures, TestTarget,Resulter=ResultInfo):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    TSCV = SKLSel.GridSearchCV(Ensemble.GradientBoostingClassifier(), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                              param_grid={\"max_depth\": [1, 2, 3, 4, 5]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.max_depth\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"== Ensemble Method Algorithm Training Optimal Parameter Selection ==\")\n",
    "    print(\"\")\n",
    "    print(\"Gradient Boosting Machine Regression A Optimal Maximum Depth: \", TCSVPar)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    XGBoostTraining = Ensemble.GradientBoostingClassifier(max_depth=TCSVPar).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Testing\n",
    "    XGBoostTesting = XGBoostTraining.predict(TestFeatures)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Forecasting\n",
    "    # Forecasting for Trading Subset\n",
    "\n",
    "    return ResultInfo(TestTarget,XGBoostTesting,MethodName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMResulter(MethodName, TrainingFeutres, TrainingTarget, TestFeatures, TestTarget,Resulter=ResultInfo):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    TSCV = SKLSel.GridSearchCV(SVM.SVC(kernel='rbf',gamma='auto'), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                              param_grid={\"C\": [0.25, 0.50, 1.00, 1.25]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.C\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"== Maximum Margin Method Algorithm Training Optimal Parameter Selection ==\")\n",
    "    print(\"\")\n",
    "    print(\"RBF Support Vector Machine Regression A Optimal Error Term Penalty: \", TCSVPar)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    SVMTraining = SVM.SVC(kernel='rbf',C=TCSVPar,gamma='auto').fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Testing\n",
    "    SVMTesting = SVMTraining.predict(TestFeatures)\n",
    "\n",
    "    # Multi-Layer Perceptron Method Forecasting\n",
    "    # Forecasting for Trading Subset\n",
    "\n",
    "    return ResultInfo(TestTarget,SVMTesting,MethodName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoostModel(TrainingFeutres, TrainingTarget):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    TSCV = SKLSel.GridSearchCV(Ensemble.GradientBoostingClassifier(), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                              param_grid={\"max_depth\": [1, 2, 3, 4, 5]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.max_depth\n",
    "\n",
    "    \n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    XGBoostTraining = Ensemble.GradientBoostingClassifier(max_depth=TCSVPar).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    return XGBoostTraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ANNModel( TrainingFeutres, TrainingTarget):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    TSCV = SKLSel.GridSearchCV(SKANN.MLPClassifier(), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                               param_grid={\"alpha\": [0.0001, 0.001, 0.010, 0.100]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.alpha\n",
    "\n",
    "    print(\"== Multi-Layer Perceptron Method Algorithm Training Optimal Parameter Selection ==\")\n",
    "    print(\"Artificial Neural Network Regression  Optimal  Regularization: \", TCSVPar)\n",
    "    print(\"\")\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    ANNTraining = SKANN.MLPClassifier(alpha=TCSVPar).fit(TrainingFeutres, TrainingTarget)\n",
    "    \n",
    "    return ANNTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMModel( TrainingFeutres, TrainingTarget):\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    # Exhaustive Grid Search Time Series Cross-Validation with Parameter Array Specification\n",
    "    # TimeSeriesSplit = anchored time series cross-validation with\n",
    "    # initial training subset = validating subset ~ n_samples / (n_splits + 1) in size\n",
    "    # alpha = L2 regularization\n",
    "\n",
    "    # 5.2.1. Time Series Cross-Validation\n",
    "    TSCV = SKLSel.GridSearchCV(SVM.SVC(kernel='rbf',gamma='auto'), cv=SKLSel.TimeSeriesSplit(n_splits=10),\n",
    "                              param_grid={\"C\": [0.25, 0.50, 1.00, 1.25]}).fit(TrainingFeutres, TrainingTarget)\n",
    "\n",
    "    #  Time Series Cross-Validation Optimal Parameter Selection\n",
    "\n",
    "    TCSVPar = TSCV.best_estimator_.C\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"== Maximum Margin Method Algorithm Training Optimal Parameter Selection ==\")\n",
    "    print(\"\")\n",
    "    print(\"RBF Support Vector Machine Regression A Optimal Error Term Penalty: \", TCSVPar)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # Multi-Layer Perceptron Method Algorithm Training\n",
    "    SVMTraining = SVM.SVC(kernel='rbf',C=TCSVPar,gamma='auto').fit(TrainingFeutres, TrainingTarget)\n",
    "    \n",
    "    return SVMTraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetResult(TestData,PredictedData,ModelName):\n",
    "    MatchData=pd.read_csv('DataSets/Match.csv')\n",
    "    MatchData.index=MatchData['id']\n",
    "    NewData=TestData.copy()\n",
    "        \n",
    "    NewData.loc[:,'Predicted']=PredictedData\n",
    "    NewData.loc[:,'BetResult']=float(0)\n",
    "    NewData.loc[:,'BetRate']=float(0)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    HomeBets=['B365H', 'BWH', 'IWH',\n",
    "       'LBH', 'PSH', 'WHH','SJH','VCH', 'GBH', 'BSH']\n",
    "\n",
    "    AwayBets=['B365A', 'BWA',  'IWA',\n",
    "          'LBA', 'PSA', 'WHA',  'SJA', 'VCA','GBA',\n",
    "           'BSA']\n",
    "\n",
    "\n",
    "    DBets=[ 'B365D', 'BWD', 'IWD', 'LBD', 'PSD', 'WHD',\n",
    "           'SJD', 'VCD',  'GBD',  'BSD']\n",
    "    \n",
    "    for index in NewData.index:\n",
    "        RealResult=NewData.loc[index,'Result']\n",
    "        PredictedResult=NewData.loc[index,'Predicted']\n",
    "\n",
    "        if PredictedResult==1:\n",
    "            Bets=MatchData.loc[index,HomeBets]\n",
    "        elif PredictedResult==-1:\n",
    "            Bets=MatchData.loc[index,AwayBets]\n",
    "        elif PredictedResult==0:\n",
    "            Bets=MatchData.loc[index,DBets]\n",
    "\n",
    "        BetRate=max(Bets)\n",
    "        NewData.at[index,'BetRate']=BetRate\n",
    "\n",
    "        if PredictedResult==RealResult:\n",
    "            NewData.at[index,'BetResult']=1\n",
    "    \n",
    "    NewData.loc[ NewData['BetResult']==0   ,'Earning']=  -100\n",
    "    NewData.loc[ NewData['BetResult']==1   ,'Earning']=   (NewData['BetRate']-1)*100\n",
    "\n",
    "    NewData.loc[:,'CumEarning']=  NewData['Earning'].cumsum()\n",
    "\n",
    "    NewData.loc[:,'Date']= pd.to_datetime( MatchData['date'])\n",
    "    \n",
    "    NewData= NewData.reset_index()\n",
    "\n",
    "    fig1, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(NewData['CumEarning'])\n",
    "\n",
    "    ax.legend(['BetEarning'])\n",
    "    plt.ylabel('Cumulative Earning')\n",
    "    plt.suptitle(ModelName)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('sdasdsa.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
